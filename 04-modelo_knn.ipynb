{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LOl_OC3QM5hsnkga6W25zeQfIEetdfet",
      "authorship_tag": "ABX9TyOZYIlvDJhpo78N3Tb/VshT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinmoreno1-ux/ENTREGAS/blob/main/04-modelo_knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Configurar rutas de archivos\n",
        "train_file_path = '/content/drive/MyDrive/IA/SaberPro/train.csv'\n",
        "test_file_path = '/content/drive/MyDrive/IA/SaberPro/test.csv'\n",
        "output_file_path = '/content/drive/MyDrive/IA/SaberPro/submission_knn.csv'\n",
        "\n",
        "print(\"=== MODELO K-NEAREST NEIGHBORS (KNN) - VERSIÓN RÁPIDA ===\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ============================================================================\n",
        "# CARGA Y PREPROCESAMIENTO\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Cargando datos de entrenamiento...\")\n",
        "try:\n",
        "    train_data = pd.read_csv(train_file_path)\n",
        "    print(f\"✓ Datos de entrenamiento cargados: {train_data.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error cargando train.csv: {e}\")\n",
        "    raise\n",
        "\n",
        "# Limpieza inicial\n",
        "if 'F_TIENEINTERNET.1' in train_data.columns:\n",
        "    train_data = train_data.drop(columns=[\"F_TIENEINTERNET.1\"])\n",
        "\n",
        "# Separar características\n",
        "numeric_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = train_data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Excluir variable objetivo e ID\n",
        "for col in ['RENDIMIENTO_GLOBAL', 'ID']:\n",
        "    if col in numeric_cols:\n",
        "        numeric_cols.remove(col)\n",
        "    if col in categorical_cols:\n",
        "        categorical_cols.remove(col)\n",
        "\n",
        "print(f\"Columnas numéricas: {len(numeric_cols)}\")\n",
        "print(f\"Columnas categóricas: {len(categorical_cols)}\")\n",
        "\n",
        "# Manejo de valores faltantes\n",
        "print(\"Aplicando preprocesamiento...\")\n",
        "train_data[numeric_cols] = train_data[numeric_cols].fillna(train_data[numeric_cols].median())\n",
        "train_data[categorical_cols] = train_data[categorical_cols].fillna('Unknown')\n",
        "\n",
        "# Codificación de variables categóricas\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    train_data[col] = le.fit_transform(train_data[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Preparar datos para entrenamiento\n",
        "X = train_data.drop(columns=[\"RENDIMIENTO_GLOBAL\", \"ID\"])\n",
        "y = train_data[\"RENDIMIENTO_GLOBAL\"]\n",
        "\n",
        "# Verificar distribución de clases\n",
        "class_distribution = y.value_counts().sort_index()\n",
        "print(f\"\\nDistribución de clases:\")\n",
        "for cls, count in class_distribution.items():\n",
        "    print(f\"  Clase {cls}: {count} muestras ({count/len(y)*100:.1f}%)\")\n",
        "\n",
        "# ============================================================================\n",
        "# PREPROCESAMIENTO ESPECIAL PARA KNN\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nAplicando escalado para KNN...\")\n",
        "# KNN es muy sensible al escalado, así que escalamos todas las características\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"✓ Datos escalados para KNN\")\n",
        "\n",
        "# Dividir para evaluación rápida (opcional, puedes eliminar esto para más velocidad)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(f\"✓ Conjunto de entrenamiento: {X_train.shape}\")\n",
        "print(f\"✓ Conjunto de validación: {X_val.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# MODELO KNN CON VALOR FIJO DE K\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nEntrenando modelo KNN con k=5...\")\n",
        "\n",
        "# Modelo KNN con valor fijo (k=5 es generalmente un buen valor por defecto)\n",
        "model = KNeighborsClassifier(\n",
        "    n_neighbors=5,        # Valor fijo - puedes cambiarlo si quieres probar otros\n",
        "    weights='distance',   # 'uniform' o 'distance' (pesa por distancia)\n",
        "    algorithm='auto',     # 'auto', 'ball_tree', 'kd_tree', 'brute'\n",
        "    leaf_size=30,\n",
        "    p=2,                  # Distancia euclidiana (p=2)\n",
        "    metric='minkowski',\n",
        "    n_jobs=-1             # Usar todos los cores\n",
        ")\n",
        "\n",
        "# Entrenar con todos los datos (más rápido que con división train/val)\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "print(\"✓ Modelo KNN entrenado exitosamente!\")\n",
        "\n",
        "# Evaluación rápida (opcional - comentar si quieres ahorrar más tiempo)\n",
        "try:\n",
        "    val_score = model.score(X_val, y_val)\n",
        "    print(f\"✓ Precisión en validación: {val_score:.4f}\")\n",
        "except:\n",
        "    print(\"✓ Evaluación de validación omitida para mayor velocidad\")\n",
        "\n",
        "# ============================================================================\n",
        "# PROCESAMIENTO DE DATOS DE PRUEBA\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nCargando datos de prueba...\")\n",
        "try:\n",
        "    test_data = pd.read_csv(test_file_path)\n",
        "    print(f\"✓ Datos de prueba cargados: {test_data.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error cargando test.csv: {e}\")\n",
        "    raise\n",
        "\n",
        "# Conservar IDs\n",
        "test_ids = test_data['ID'].copy()\n",
        "\n",
        "# Limpieza inicial\n",
        "if 'F_TIENEINTERNET.1' in test_data.columns:\n",
        "    test_data = test_data.drop(columns=[\"F_TIENEINTERNET.1\"])\n",
        "\n",
        "# Asegurar que las columnas coincidan\n",
        "missing_cols = set(X.columns) - set(test_data.columns)\n",
        "if missing_cols:\n",
        "    print(f\"⚠ Columnas faltantes en test: {missing_cols}\")\n",
        "    for col in missing_cols:\n",
        "        test_data[col] = 0\n",
        "\n",
        "extra_cols = set(test_data.columns) - set(X.columns) - {'ID'}\n",
        "if extra_cols:\n",
        "    print(f\"⚠ Columnas adicionales en test: {extra_cols}\")\n",
        "    test_data = test_data.drop(columns=extra_cols)\n",
        "\n",
        "test_data = test_data[X.columns.tolist() + ['ID']]\n",
        "\n",
        "# Aplicar mismo preprocesamiento\n",
        "test_data[numeric_cols] = test_data[numeric_cols].fillna(train_data[numeric_cols].median())\n",
        "\n",
        "# Codificar variables categóricas con los mismos encoders\n",
        "for col in categorical_cols:\n",
        "    if col in test_data.columns and col in label_encoders:\n",
        "        test_data[col] = test_data[col].astype(str)\n",
        "        # Manejar valores no vistos\n",
        "        unknown_mask = ~test_data[col].isin(label_encoders[col].classes_)\n",
        "        if unknown_mask.any():\n",
        "            # Reemplazar con el valor más frecuente\n",
        "            most_frequent = label_encoders[col].classes_[0]\n",
        "            test_data.loc[unknown_mask, col] = most_frequent\n",
        "        test_data[col] = label_encoders[col].transform(test_data[col])\n",
        "\n",
        "# Preparar datos de prueba\n",
        "X_test = test_data.drop(columns=['ID'])\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ============================================================================\n",
        "# PREDICCIÓN Y ANÁLISIS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Realizando predicciones...\")\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Análisis de las predicciones\n",
        "unique_preds, counts = np.unique(y_pred, return_counts=True)\n",
        "print(f\"\\nDistribución de predicciones:\")\n",
        "for pred, count in zip(unique_preds, counts):\n",
        "    percentage = count/len(y_pred)*100\n",
        "    print(f\"  Clase {pred}: {count:6d} muestras ({percentage:5.1f}%)\")\n",
        "\n",
        "# ============================================================================\n",
        "# GUARDAR RESULTADOS\n",
        "# ============================================================================\n",
        "\n",
        "# Crear archivo de submission\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': y_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(output_file_path, index=False)\n",
        "print(f\"\\n✓ Archivo de submission guardado en: {output_file_path}\")\n",
        "print(f\"✓ Total de predicciones: {len(y_pred)}\")\n",
        "\n",
        "# Información adicional del modelo\n",
        "print(f\"\\nConfiguración del modelo KNN:\")\n",
        "print(f\"  Número de vecinos (k): 5 (fijo)\")\n",
        "print(f\"  Métrica de distancia: {model.metric}\")\n",
        "print(f\"  Peso: {model.weights}\")\n",
        "\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0QHguL3UoSf",
        "outputId": "e2dd78f0-3b3f-4b70-e21f-24ede8147016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "=== MODELO K-NEAREST NEIGHBORS (KNN) - VERSIÓN RÁPIDA ===\n",
            "======================================================================\n",
            "Cargando datos de entrenamiento...\n",
            "✓ Datos de entrenamiento cargados: (692500, 21)\n",
            "Columnas numéricas: 5\n",
            "Columnas categóricas: 13\n",
            "Aplicando preprocesamiento...\n",
            "\n",
            "Distribución de clases:\n",
            "  Clase alto: 175619 muestras (25.4%)\n",
            "  Clase bajo: 172987 muestras (25.0%)\n",
            "  Clase medio-alto: 171619 muestras (24.8%)\n",
            "  Clase medio-bajo: 172275 muestras (24.9%)\n",
            "\n",
            "Aplicando escalado para KNN...\n",
            "✓ Datos escalados para KNN\n",
            "✓ Conjunto de entrenamiento: (554000, 18)\n",
            "✓ Conjunto de validación: (138500, 18)\n",
            "\n",
            "Entrenando modelo KNN con k=5...\n",
            "✓ Modelo KNN entrenado exitosamente!\n",
            "✓ Precisión en validación: 1.0000\n",
            "\n",
            "Cargando datos de prueba...\n",
            "✓ Datos de prueba cargados: (296786, 20)\n",
            "Realizando predicciones...\n"
          ]
        }
      ]
    }
  ]
}