{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPnrWTp/xpL1gpMhk13lCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinmoreno1-ux/ENTREGAS/blob/main/99-modelo_solucion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OFYx4KtXvDr",
        "outputId": "d782af99-477e-4950-bb3c-d3d377027f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "=== MODELO DE PREDICCIÓN DE RENDIMIENTO ACADÉMICO ===\n",
            "======================================================================\n",
            "Cargando datos de entrenamiento...\n",
            "✓ Datos de entrenamiento cargados: (692500, 21)\n",
            "Columnas numéricas: 5\n",
            "Columnas categóricas: 13\n",
            "Aplicando preprocesamiento...\n",
            "Entrenando modelo Random Forest...\n",
            "✓ Modelo entrenado exitosamente!\n",
            "✓ Tamaño del conjunto de entrenamiento: (692500, 18)\n",
            "\n",
            "Cargando datos de prueba...\n",
            "✓ Datos de prueba cargados: (296786, 20)\n",
            "⚠ Valores no vistos en E_PRGM_ACADEMICO: {'COMUNICACIÖN SOCIAL', 'AGROINDUSTRIA', 'LICENC.EN EDUCACION BASICA PRIMARIA ENF.EN CIENCIAS NATURALESEDUC.AMBIENTAL MATEMA.LENGUA CASTELLANA', 'LICENCIATURA EN MATEMATICA E INFORMATICA', 'NEGOCIOS INTERNACIONALES BILINGUE', 'LICENCIATURA EN EDUCACION ENFASIS EN HUMANIDADES', 'LICENCIATURA EN EDUCACION BASICA CON ENFASIS EN IDIOMAS EXTRANJEROS', 'ADMINISTRACION DE EMPRESAS.', 'ARTE DRAMÁTICO', 'ADMINISTRACION  DE EMPRESAS.'}\n",
            "Realizando predicciones...\n",
            "✓ Archivo de submission guardado en: /content/drive/MyDrive/IA/SaberPro/submission_solucion.csv\n",
            "✓ Total de predicciones: 296786\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Especificar las rutas a los archivos\n",
        "train_file_path = '/content/drive/MyDrive/IA/SaberPro/train.csv'\n",
        "test_file_path = '/content/drive/MyDrive/IA/SaberPro/test.csv'  # Asegúrate de que este archivo existe\n",
        "output_file_path = '/content/drive/MyDrive/IA/SaberPro/submission_solucion.csv'  # Ruta para guardar resultados\n",
        "\n",
        "print(\"=== MODELO DE PREDICCIÓN DE RENDIMIENTO ACADÉMICO ===\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ============================================================================\n",
        "# PROCESAMIENTO DE DATOS DE ENTRENAMIENTO\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Cargando datos de entrenamiento...\")\n",
        "try:\n",
        "    train_data = pd.read_csv(train_file_path)\n",
        "    print(f\"✓ Datos de entrenamiento cargados: {train_data.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error cargando train.csv: {e}\")\n",
        "    raise\n",
        "\n",
        "# Limpieza inicial: eliminar columna duplicada si existe\n",
        "if 'F_TIENEINTERNET.1' in train_data.columns:\n",
        "    train_data = train_data.drop(columns=[\"F_TIENEINTERNET.1\"])\n",
        "\n",
        "# Separar características numéricas y categóricas\n",
        "numeric_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = train_data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Excluir variable objetivo e ID\n",
        "if 'RENDIMIENTO_GLOBAL' in numeric_cols:\n",
        "    numeric_cols.remove('RENDIMIENTO_GLOBAL')\n",
        "if 'RENDIMIENTO_GLOBAL' in categorical_cols:\n",
        "    categorical_cols.remove('RENDIMIENTO_GLOBAL')\n",
        "if 'ID' in numeric_cols:\n",
        "    numeric_cols.remove('ID')\n",
        "if 'ID' in categorical_cols:\n",
        "    categorical_cols.remove('ID')\n",
        "\n",
        "print(f\"Columnas numéricas: {len(numeric_cols)}\")\n",
        "print(f\"Columnas categóricas: {len(categorical_cols)}\")\n",
        "\n",
        "# Manejo de valores faltantes\n",
        "print(\"Aplicando preprocesamiento...\")\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "train_data[numeric_cols] = imputer_num.fit_transform(train_data[numeric_cols])\n",
        "train_data[categorical_cols] = imputer_cat.fit_transform(train_data[categorical_cols])\n",
        "\n",
        "# Codificación de variables categóricas\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    try:\n",
        "        le = LabelEncoder()\n",
        "        train_data[col] = le.fit_transform(train_data[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "    except Exception as e:\n",
        "        print(f\"Error codificando {col}: {e}\")\n",
        "        train_data = train_data.drop(columns=[col])\n",
        "        if col in categorical_cols:\n",
        "            categorical_cols.remove(col)\n",
        "\n",
        "# Preparar datos para entrenamiento\n",
        "X_train = train_data.drop(columns=[\"RENDIMIENTO_GLOBAL\", \"ID\"])\n",
        "y_train = train_data[\"RENDIMIENTO_GLOBAL\"]\n",
        "\n",
        "# Estandarización de características numéricas\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "\n",
        "\n",
        "\n",
        "#Entrenamiento del modelo\n",
        "print(\"Entrenando modelo Random Forest...\")\n",
        "#model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "#model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Entrenamiento del modelo (Variando hiperparametros)\n",
        "\n",
        "# print(\"Entrenando modelo Random Forest...\")\n",
        "# model = RandomForestClassifier(n_estimators=200,\n",
        "#                               max_depth=20,\n",
        "#                               min_samples_split=10,\n",
        "#                               min_samples_leaf=5,\n",
        "#                               class_weight='balanced',\n",
        "#                               random_state=42,\n",
        "#                               n_jobs=-1)\n",
        "\n",
        "# model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Entrenamiento del modelo (Variando hiperparametros)\n",
        "\n",
        "#print(\"Entrenando modelo Random Forest...\")\n",
        "#model = RandomForestClassifier(\n",
        "#    n_estimators=280,\n",
        "#    max_depth=28,\n",
        "#    min_samples_split=4,\n",
        "#    min_samples_leaf=1,\n",
        "#    max_features=0.5,\n",
        "#    bootstrap=True,\n",
        "#    class_weight='balanced',\n",
        "#    random_state=42,\n",
        "#    n_jobs=-1)\n",
        "\n",
        "#model.fit(X_train_scaled, y_train)\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=150,\n",
        "    max_depth=15,\n",
        "    min_samples_split=3,\n",
        "    min_samples_leaf=1,\n",
        "    max_features=0.7,\n",
        "    bootstrap=True,\n",
        "    random_state=42,\n",
        "    n_jobs=-1)\n",
        "\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"✓ Modelo entrenado exitosamente!\")\n",
        "print(f\"✓ Tamaño del conjunto de entrenamiento: {X_train_scaled.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PROCESAMIENTO DE DATOS DE PRUEBA Y PREDICCIÓN\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nCargando datos de prueba...\")\n",
        "try:\n",
        "    test_data = pd.read_csv(test_file_path)\n",
        "    print(f\"✓ Datos de prueba cargados: {test_data.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error cargando test.csv: {e}\")\n",
        "    raise\n",
        "\n",
        "# Conservar IDs para la submission\n",
        "test_ids = test_data['ID'].copy()\n",
        "\n",
        "# Aplicar misma limpieza inicial\n",
        "if 'F_TIENEINTERNET.1' in test_data.columns:\n",
        "    test_data = test_data.drop(columns=[\"F_TIENEINTERNET.1\"])\n",
        "\n",
        "# Asegurar que las columnas coincidan con el entrenamiento\n",
        "missing_cols = set(X_train.columns) - set(test_data.columns)\n",
        "if missing_cols:\n",
        "    print(f\"✗ Columnas faltantes en test: {missing_cols}\")\n",
        "    raise ValueError(\"Faltan columnas en el conjunto de prueba\")\n",
        "\n",
        "extra_cols = set(test_data.columns) - set(X_train.columns) - {'ID'}\n",
        "if extra_cols:\n",
        "    print(f\"⚠ Columnas adicionales en test: {extra_cols}\")\n",
        "\n",
        "# Reordenar columnas para coincidir con el entrenamiento\n",
        "test_data = test_data[X_train.columns.tolist() + ['ID']]\n",
        "\n",
        "# Aplicar imputación con los mismos parámetros de entrenamiento\n",
        "test_data[numeric_cols] = imputer_num.transform(test_data[numeric_cols])\n",
        "test_data[categorical_cols] = imputer_cat.transform(test_data[categorical_cols])\n",
        "\n",
        "# Codificar variables categóricas con los mismos encoders\n",
        "for col in categorical_cols:\n",
        "    if col in label_encoders:\n",
        "        # Manejar valores no vistos asignándoles un valor común\n",
        "        unique_values = set(test_data[col].astype(str))\n",
        "        unknown_values = unique_values - set(label_encoders[col].classes_)\n",
        "        if unknown_values:\n",
        "            print(f\"⚠ Valores no vistos en {col}: {unknown_values}\")\n",
        "            # Asignar el valor más frecuente del entrenamiento\n",
        "            most_frequent = label_encoders[col].classes_[0]\n",
        "            test_data[col] = test_data[col].apply(\n",
        "                lambda x: x if x in label_encoders[col].classes_ else most_frequent\n",
        "            )\n",
        "        test_data[col] = label_encoders[col].transform(test_data[col].astype(str))\n",
        "\n",
        "# Estandarización con el scaler de entrenamiento\n",
        "X_test_scaled = test_data.drop(columns=['ID'])\n",
        "X_test_scaled[numeric_cols] = scaler.transform(X_test_scaled[numeric_cols])\n",
        "\n",
        "# Realizar predicciones\n",
        "print(\"Realizando predicciones...\")\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Crear archivo de submission\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': y_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(output_file_path, index=False)\n",
        "print(f\"✓ Archivo de submission guardado en: {output_file_path}\")\n",
        "print(f\"✓ Total de predicciones: {len(y_pred)}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ilEHYdsXZPMd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}